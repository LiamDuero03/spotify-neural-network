{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf81edba-5ef6-42da-ae1c-29dc9401fadf",
   "metadata": {},
   "source": [
    "# üéØ Benchmarking with Random Forest  \n",
    "\n",
    "In this notebook, we‚Äôll build a **baseline model** to predict **weekly S&P 500 closing values** (`sp500_close`) using Spotify audio features.  \n",
    "\n",
    "Before creating a Neural Network, we first set a benchmark using a **Random Forest Regressor**.  \n",
    "\n",
    "‚úÖ **Why start with Random Forest?**  \n",
    "- It‚Äôs a strong, non-linear model that often performs well without heavy preprocessing.  \n",
    "- It gives a quick baseline to see if there‚Äôs a meaningful relationship between music trends & the stock market.  \n",
    "- We can later compare the Neural Network‚Äôs performance against this benchmark.  \n",
    "\n",
    "We‚Äôll evaluate the model using:  \n",
    "- **MAE (Mean Absolute Error)** ‚Üí average prediction error  \n",
    "- **RMSE (Root Mean Squared Error)** ‚Üí penalizes larger errors more  \n",
    "- **R¬≤ score** ‚Üí how much variance in the target is explained by the model  \n",
    "\n",
    "---\n",
    "\n",
    "## üìÇ Step 1: Load Prepared Dataset  \n",
    "\n",
    "We load the `merged_spotify_sp500_weekly.csv` file created in the previous notebook.  \n",
    "This dataset contains:  \n",
    "- **Spotify weekly aggregated audio features**  \n",
    "- **Weekly S&P 500 closing values (`sp500_close`)**  \n",
    "\n",
    "We‚Äôll use this as the input for feature selection and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82df2cd6-db4d-4c61-9e8f-f9fd0fa43b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded successfully!\n",
      "Shape: (1096, 17)\n",
      "         week  popularity    duration_ms  explicit  danceability    energy  \\\n",
      "0  2000-01-03   35.513665  236354.200000  0.021739      0.584862  0.634662   \n",
      "1  2000-01-10   24.194030  264388.388060  0.000000      0.579485  0.473000   \n",
      "2  2000-01-17   35.553398  314967.650485  0.029126      0.564311  0.601623   \n",
      "3  2000-01-24   29.603774  234980.283019  0.207547      0.579434  0.606309   \n",
      "4  2000-01-31   33.893617  242338.063830  0.042553      0.614447  0.645043   \n",
      "\n",
      "        key   loudness      mode  speechiness  acousticness  instrumentalness  \\\n",
      "0  5.288820  -8.272797  0.668944     0.063389      0.315100          0.056376   \n",
      "1  5.194030 -11.943164  0.537313     0.081290      0.525509          0.114000   \n",
      "2  5.388350  -9.865961  0.553398     0.090569      0.387647          0.174762   \n",
      "3  5.754717  -8.492604  0.660377     0.087913      0.304237          0.034134   \n",
      "4  5.595745  -8.106702  0.531915     0.045194      0.337882          0.092659   \n",
      "\n",
      "   liveness   valence       tempo  time_signature  sp500_close  \n",
      "0  0.204088  0.578023  120.737025        3.897516  1441.469971  \n",
      "1  0.251379  0.592707  109.798746        3.835821  1465.150024  \n",
      "2  0.270982  0.577487  116.097049        3.941748  1441.359985  \n",
      "3  0.234036  0.520987  118.133472        3.811321  1360.160034  \n",
      "4  0.214879  0.615128  121.556000        4.042553  1424.369995  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Load the prepared merged dataset\n",
    "data_path = \"merged_spotify_sp500_weekly.csv\"\n",
    "merged = pd.read_csv(data_path)\n",
    "\n",
    "print(\"‚úÖ Dataset loaded successfully!\")\n",
    "print(\"Shape:\", merged.shape)\n",
    "print(merged.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af962e-b703-4822-a270-83e20376e025",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Step 2: Define Features & Target + Train/Test Split  \n",
    "\n",
    "Now we prepare the data for modeling:  \n",
    "\n",
    "- **Target (`y`)** ‚Üí `sp500_close` (weekly S&P 500 closing value)  \n",
    "- **Features (`X`)** ‚Üí all Spotify audio features (e.g., `danceability`, `energy`, `valence`, etc.)  \n",
    "\n",
    "We then split the dataset into:  \n",
    "- **Training set (80%)** ‚Üí used for fitting the model  \n",
    "- **Test set (20%)** ‚Üí held out for final performance evaluation  \n",
    "\n",
    "üìå **Important:**  \n",
    "Since this is a **time-series-like problem**, we **do NOT shuffle** the data when splitting.  \n",
    "This preserves the chronological order and avoids data leakage from the future.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e8a8c1-e9cb-416c-82a4-d9b4b92bfa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used: ['popularity', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\n",
      "X shape: (1096, 15) | y shape: (1096,)\n",
      "Train size: 876 | Test size: 220\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ‚úÖ Define target (y) and features (X)\n",
    "target = \"sp500_close\"\n",
    "feature_cols = [col for col in merged.columns if col not in [\"week\", target]]\n",
    "\n",
    "X = merged[feature_cols]\n",
    "y = merged[target]\n",
    "\n",
    "print(\"Features used:\", feature_cols)\n",
    "print(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n",
    "\n",
    "# ‚úÖ Train/Test Split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False  # no shuffle to preserve time-series order\n",
    ")\n",
    "\n",
    "print(f\"Train size: {X_train.shape[0]} | Test size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af52e48-668d-4ddd-88c8-ed6e4329c3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a40484-f441-4d5d-ab46-5b9df09f2832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
